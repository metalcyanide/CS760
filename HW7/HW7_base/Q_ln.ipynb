{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nA = 2\n",
    "nS = 2\n",
    "Q_table = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in range(nS):\n",
    "        # Q_table[state] = np.random.random(nA)\n",
    "        Q_table[state] = np.zeros(nA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(s, a, r, s_n, alpha=0.5, gamma=0.8):\n",
    "    curr_q_val = Q_table[s][a]\n",
    "    max_q_val = np.max(Q_table[s_n])\n",
    "    update_q_val = (1-alpha)*curr_q_val + alpha*(r + gamma*max_q_val)\n",
    "    Q_table[s][a] = update_q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action(state, epsilon=0.5, no_preference=True):\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.choice(nA) \n",
    "    else:\n",
    "        if no_preference:\n",
    "            action = np.argmax(Q_table[state])\n",
    "            return action\n",
    "        else:\n",
    "            if Q_table[state][0] > Q_table[state][1]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "            \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(current_state, action):\n",
    "    # action is 0 means move, 1 means stay\n",
    "    return (current_state+action+1)%2, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = 0 a = 0 s_next, reward = (1, 0)\n",
      "s = 0 a = 1 s_next, reward = (0, 1)\n",
      "s = 1 a = 0 s_next, reward = (0, 0)\n",
      "s = 1 a = 1 s_next, reward = (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for state in range(nS):\n",
    "    for action in range(nA):\n",
    "        print(f's = {state} a = {action} s_next, reward = {step(state,action)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "def train(num_episodes=200, epsilon=0.5, gamma=0.8, alpha=0.5, nS=2, nA=2, no_pref=True):\n",
    "    for state in range(nS):\n",
    "        # Q_table[state] = np.random.random(nA)\n",
    "        Q_table[state] = np.zeros(nA)\n",
    "    for _ in range(num_episodes):\n",
    "        # Randomly choose an initial state\n",
    "        current_state = np.random.choice(nS)\n",
    "        while True:\n",
    "            action = greedy_action(current_state, epsilon, no_pref)\n",
    "\n",
    "            next_state, reward = step(current_state, action)\n",
    "            \n",
    "            q_learning(current_state, action, reward, next_state, alpha, gamma)\n",
    "\n",
    "            current_state = next_state\n",
    "\n",
    "            # Check if the episode is finished\n",
    "            if next_state == current_state:\n",
    "                break\n",
    "    print(Q_table)\n",
    "    return Q_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([3.99384751, 4.99632871]), 1: array([3.99616373, 4.99587546])}\n"
     ]
    }
   ],
   "source": [
    "Q_table_part_2 = train(200, epsilon=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0.50207421, 4.99988099]), 1: array([0.31254453, 4.99983755])}\n"
     ]
    }
   ],
   "source": [
    "Q_table_part_1 = train(200, epsilon=0.0, no_pref=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State(s) & Action(a) & Q_value(s,a) \\\\\n",
      "A & Move & 0.502074212609357 \\\\\n",
      "A & Stay & 4.999880987753604 \\\\\n",
      "B & Move & 0.3125445271283821 \\\\\n",
      "B & Stay & 4.999837549288073 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(f'State(s) & Action(a) & Q_value(s,a) \\\\\\\\')\n",
    "for state in Q_table_part_2.keys():\n",
    "    state_val = 'A' if state == 0 else 'B'\n",
    "    for id in range(len(Q_table_part_2[state])):\n",
    "        if id == 0:\n",
    "            action_val = 'Move'\n",
    "        else:\n",
    "            action_val = 'Stay'\n",
    "        print(f'{state_val} & {action_val} & {Q_table_part_2[state][id]} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([0., 0.]), 1: array([0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "Q_table_part_2 = train(200, epsilon=0.0, no_pref=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
